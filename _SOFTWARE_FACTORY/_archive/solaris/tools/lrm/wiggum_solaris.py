#!/usr/bin/env python3
"""
WIGGUM SOLARIS - Agent it√©ratif avec contr√¥le Adversarial
==========================================================
D√©pile les t√¢ches du backlog et g√©n√®re/corrige le code.

WIGGUM: MiniMax via opencode (it√©rations rapides)
ADVERSARIAL: Contr√¥le qualit√© apr√®s chaque it√©ration

Cycle:
1. Lit t√¢che du backlog
2. G√©n√®re code (MiniMax)
3. V√©rifie via Adversarial Agent
4. Si SLOP/FAKE d√©tect√© ‚Üí retry avec feedback
5. Si OK ‚Üí valide via ./solaris validate
6. Complete ou escalate

Usage:
    python3 tools/lrm/wiggum_solaris.py [--daemon]
"""

import asyncio
import json
import os
import re
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional, Tuple

# Configuration
PROJECT_ROOT = Path("/Users/sylvain/_LAPOSTE/_SD3")
LOGS_DIR = PROJECT_ROOT / "logs" / "lrm"
TASKS_DIR = PROJECT_ROOT / "tools" / "lrm" / "tasks"
BACKLOG_FILE = PROJECT_ROOT / "tools" / "lrm" / "backlog_solaris.json"
COMPLETED_FILE = PROJECT_ROOT / "tools" / "lrm" / "completed_solaris.json"

# LLM Config - MiniMax M2.1 via opencode (Coding Plan)
MINIMAX_MODEL = "opencode/minimax-m2.1-free"  # Primary: MiniMax M2.1 Coding Plan

# Fallback: Qwen3 local via llama-cpp (port 8002)
QWEN3_BASE_URL = "http://localhost:8002/v1"
QWEN3_MODEL = "Qwen3-30B-A3B-Instruct-Q4_K_S.gguf"
USE_MINIMAX = True  # Use MiniMax M2.1 via opencode (1000 prompts/5h)

# Retry config
MAX_RETRIES = 10  # Augment√© pour plus d'it√©rations
RETRY_DELAY = 2

# Fractal config - d√©composition automatique si t√¢che trop large
FRACTAL_ENABLED = True
FRACTAL_THRESHOLDS = {
    "max_components": 3,      # Plus de 3 composants = d√©composer
    "max_criteria": 5,        # Plus de 5 crit√®res = d√©composer
    "max_files": 5,           # Plus de 5 fichiers = d√©composer
    "max_loc_estimate": 200,  # Plus de 200 LOC estim√©es = d√©composer
}
FRACTAL_MAX_DEPTH = 3  # Profondeur max de r√©cursion fractale

# Ensure directories exist
LOGS_DIR.mkdir(parents=True, exist_ok=True)
TASKS_DIR.mkdir(parents=True, exist_ok=True)


def log(msg: str):
    """Log with timestamp"""
    ts = datetime.now().strftime("%H:%M:%S")
    print(f"[{ts}] {msg}")


class AdversarialAgent:
    """
    Agent Adversarial - D√©tecte SLOP, FAKE, HALLUCINATIONS
    
    Patterns d√©tect√©s:
    - test.skip / @ts-ignore / TODO / STUB
    - Valeurs hardcod√©es sans source Figma
    - Mensonges ("100%", "perfect", "no issues")
    - Code incomplet (... / pass / NotImplemented)
    """
    
    SLOP_PATTERNS = [
        # CRITICAL - Contournements (score √©lev√©)
        (r"test\.skip", 10, "test.skip INTERDIT - tests contourn√©s"),
        (r"it\.skip|describe\.skip", 10, "skip INTERDIT - tests contourn√©s"),
        (r"@ts-ignore", 5, "@ts-ignore d√©tect√© - types contourn√©s"),
        (r"\.unwrap\(\)", 2, "unwrap() sans gestion d'erreur"),
        (r"type\s*=\s*['\"]any['\"]", 3, "type 'any' d√©tect√©"),
        (r"TODO|FIXME|STUB|HACK", 4, "TODO/STUB d√©tect√© - code incomplet"),
        (r"NotImplemented|pass\s*$", 5, "NotImplemented/pass - fonction vide"),
        (r"\.\.\.", 3, "... d√©tect√© - code tronqu√©"),
        (r"hardcoded|magic number", 3, "Valeur hardcod√©e"),
        (r"expect\([^)]+\)\.toBe\(\d+\)", 2, "Valeur de test hardcod√©e"),
        # OVERCONFIDENT CLAIMS - Affirmations suspectes
        (r"\b(ensures?|guaranteed?|always)\b", 3, "OVERCONFIDENT: 'ensures/guarantees' - affirmation non prouv√©e"),
        (r"\b(perfect|flawless|100%)\b", 5, "OVERCONFIDENT: 'perfect/100%' - affirmation suspecte"),
        (r"\b(no issues?|no problems?|all good)\b", 4, "OVERCONFIDENT: 'no issues' - affirmation suspecte"),
        (r"\b(complete|comprehensive|exhaustive)\b", 2, "OVERCONFIDENT: 'complete' - √† v√©rifier"),
        (r"\bfully\s+(tested|validated|compliant)\b", 4, "OVERCONFIDENT: 'fully tested' - √† prouver"),
        (r"\bsolves?\s+all\b", 4, "OVERCONFIDENT: 'solves all' - affirmation exag√©r√©e"),
    ]
    
    HALLUCINATION_PATTERNS = [
        (r"borderRadius:\s*['\"]?\d+px['\"]?", 3, "borderRadius hardcod√© - doit venir de Figma"),
        (r"padding:\s*['\"]?\d+px['\"]?", 2, "padding hardcod√© - doit venir de Figma"),
        (r"color:\s*#[0-9a-fA-F]{6}", 2, "couleur hardcod√©e - doit venir de tokens"),
    ]
    
    def __init__(self):
        self.threshold = 5  # Score au-del√† duquel on rejette
    
    def analyze(self, code: str, task_description: str = "") -> Tuple[bool, int, list]:
        """
        Analyse le code pour d√©tecter SLOP/FAKE/HALLUCINATIONS
        
        Returns:
            (approved, score, issues)
        """
        issues = []
        total_score = 0
        
        # Check SLOP patterns
        for pattern, score, msg in self.SLOP_PATTERNS:
            matches = re.findall(pattern, code, re.IGNORECASE | re.MULTILINE)
            if matches:
                count = len(matches)
                total_score += score * count
                issues.append(f"SLOP: {msg} ({count}x, +{score * count} pts)")
        
        # Check HALLUCINATION patterns
        for pattern, score, msg in self.HALLUCINATION_PATTERNS:
            matches = re.findall(pattern, code, re.IGNORECASE)
            if matches:
                count = len(matches)
                total_score += score * count
                issues.append(f"HALLUCINATION: {msg} ({count}x, +{score * count} pts)")
        
        # Check for empty or too short response
        if len(code.strip()) < 50:
            total_score += 10
            issues.append("FAKE: R√©ponse trop courte (<50 chars)")
        
        # Check for error messages
        if code.startswith("Error:"):
            total_score += 10
            issues.append(f"ERROR: {code[:100]}")
        
        approved = total_score < self.threshold
        
        return approved, total_score, issues
    
    def format_feedback(self, issues: list) -> str:
        """Format issues as feedback for retry"""
        if not issues:
            return ""
        
        feedback = "‚ùå ADVERSARIAL REJECTION:\n"
        for issue in issues:
            feedback += f"  - {issue}\n"
        feedback += "\nCORRECTIONS REQUISES:\n"
        feedback += "  1. Utiliser les vraies valeurs Figma via MCP solaris_variant()\n"
        feedback += "  2. Pas de valeurs hardcod√©es\n"
        feedback += "  3. Pas de test.skip, TODO, STUB\n"
        feedback += "  4. Code complet et fonctionnel\n"
        
        return feedback


class WiggumSolaris:
    """
    Wiggum Agent - Ex√©cute les t√¢ches du backlog avec mode FRACTAL
    
    Cycle par t√¢che:
    1. √âvalue si t√¢che trop large ‚Üí FRACTAL decompose
    2. Charge contexte via MCP
    3. G√©n√®re code via MiniMax
    4. V√©rifie via Adversarial
    5. Retry si rejet√© (max 10x)
    6. Valide via ./solaris validate
    
    Mode FRACTAL (MIT CSAIL arXiv:2512.24601):
    - Si t√¢che d√©passe les seuils ‚Üí d√©compose en sous-t√¢ches
    - Chaque sous-t√¢che est trait√©e r√©cursivement
    - Profondeur max: 3 niveaux
    - √âvite le code partiel en bornant le scope
    """
    
    def __init__(self):
        self.adversarial = AdversarialAgent()
        self.completed = []
        self.failed = []
        self.subtasks_queue = []  # Queue pour sous-t√¢ches fractales
    
    def should_decompose(self, task: dict) -> bool:
        """
        V√©rifie si une t√¢che d√©passe les seuils et doit √™tre d√©compos√©e.
        Mode FRACTAL - √©vite le code partiel.
        """
        if not FRACTAL_ENABLED:
            return False
        
        components = task.get("components", [])
        criteria = task.get("acceptance_criteria", [])
        files = task.get("files", [])
        depth = task.get("fractal_depth", 0)
        
        # Ne pas d√©composer au-del√† de la profondeur max
        if depth >= FRACTAL_MAX_DEPTH:
            return False
        
        # V√©rifier les seuils
        if len(components) > FRACTAL_THRESHOLDS["max_components"]:
            log(f"   üîÄ FRACTAL: {len(components)} components > {FRACTAL_THRESHOLDS['max_components']} ‚Üí d√©composition")
            return True
        
        if len(criteria) > FRACTAL_THRESHOLDS["max_criteria"]:
            log(f"   üîÄ FRACTAL: {len(criteria)} criteria > {FRACTAL_THRESHOLDS['max_criteria']} ‚Üí d√©composition")
            return True
        
        if len(files) > FRACTAL_THRESHOLDS["max_files"]:
            log(f"   üîÄ FRACTAL: {len(files)} files > {FRACTAL_THRESHOLDS['max_files']} ‚Üí d√©composition")
            return True
        
        return False
    
    async def decompose_task(self, task: dict) -> list:
        """
        D√©compose une t√¢che trop large en sous-t√¢ches atomiques.
        Utilise le LLM pour une d√©composition intelligente.
        """
        task_id = task.get("id", "UNKNOWN")
        description = task.get("description", "")
        components = task.get("components", [])
        criteria = task.get("acceptance_criteria", [])
        depth = task.get("fractal_depth", 0)
        
        log(f"   üîÄ FRACTAL DECOMPOSE {task_id} (depth={depth})")
        
        # Prompt pour d√©composition
        decompose_prompt = f"""Tu es un expert en d√©composition de t√¢ches.

T√ÇCHE PARENT: {description}
COMPOSANTS: {', '.join(components)}
CRIT√àRES: {chr(10).join(f'- {c}' for c in criteria)}

R√àGLES DE D√âCOMPOSITION:
1. Chaque sous-t√¢che doit √™tre ATOMIQUE (1-3 composants max)
2. Chaque sous-t√¢che doit √™tre IND√âPENDANTE et d√©ployable seule
3. Chaque sous-t√¢che doit avoir des crit√®res d'acceptation MESURABLES
4. Maximum 5 sous-t√¢ches

Retourne un JSON valide avec ce format exact:
{{
  "subtasks": [
    {{
      "id": "{task_id}-1",
      "description": "...",
      "components": ["..."],
      "acceptance_criteria": ["..."],
      "files": ["..."]
    }}
  ]
}}

JSON:"""
        
        response = await self.call_wiggum(decompose_prompt)
        
        # Parser le JSON
        try:
            # Extraire le JSON de la r√©ponse
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                data = json.loads(json_match.group())
                subtasks = data.get("subtasks", [])
                
                # Ajouter la profondeur fractale
                for st in subtasks:
                    st["fractal_depth"] = depth + 1
                    st["parent_task"] = task_id
                
                log(f"   ‚úÖ D√©compos√© en {len(subtasks)} sous-t√¢ches")
                return subtasks
        except json.JSONDecodeError as e:
            log(f"   ‚ö†Ô∏è Erreur parsing JSON: {e}")
        
        # Fallback: d√©composition simple par composant
        subtasks = []
        for i, comp in enumerate(components[:5]):
            subtasks.append({
                "id": f"{task_id}-{i+1}",
                "description": f"Impl√©menter {comp} pour: {description[:100]}",
                "components": [comp],
                "acceptance_criteria": criteria[:2],
                "fractal_depth": depth + 1,
                "parent_task": task_id
            })
        
        log(f"   ‚ö†Ô∏è Fallback: d√©compos√© en {len(subtasks)} sous-t√¢ches par composant")
        return subtasks
    
    async def call_wiggum(self, prompt: str) -> str:
        """Appel MiniMax M2.1 via opencode CLI (Coding Plan) avec fallback Qwen3 local"""
        import aiohttp
        
        if USE_MINIMAX:
            # Try MiniMax M2.1 via opencode first
            try:
                proc = await asyncio.create_subprocess_exec(
                    "opencode", "run", "-m", MINIMAX_MODEL,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE,
                    stdin=asyncio.subprocess.PIPE,
                )
                stdout, stderr = await asyncio.wait_for(
                    proc.communicate(input=prompt.encode()),
                    timeout=3600,  # 1h timeout
                )
                
                if proc.returncode == 0 and stdout:
                    return stdout.decode()[:20000]
                # Fallback to Qwen3 local if MiniMax fails
                log("   MiniMax failed, falling back to Qwen3 local")
            except asyncio.TimeoutError:
                log("   MiniMax timeout, falling back to Qwen3 local")
            except Exception as e:
                log(f"   MiniMax error ({e}), falling back to Qwen3 local")
        
        # Fallback: Qwen3 local via HTTP (llama-cpp)
        headers = {"Content-Type": "application/json"}
        payload = {
            "model": QWEN3_MODEL,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 4096,
            "temperature": 0.3
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{QWEN3_BASE_URL}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=3600)  # 1h for complex prompts
                ) as resp:
                    data = await resp.json()
                    
                    if resp.status == 200:
                        choices = data.get("choices", [])
                        if choices:
                            return choices[0].get("message", {}).get("content", "")[:20000]
                        return str(data)[:20000]
                    else:
                        error = data.get("error", {}).get("message", str(data))
                        return f"Error: Qwen3 returned {resp.status} - {error}"
        except asyncio.TimeoutError:
            return "Error: Wiggum timeout (1h)"
        except aiohttp.ClientConnectorError:
            return "Error: Qwen3 server not running (port 8002)"
        except Exception as e:
            return f"Error: {e}"
    
    async def get_figma_context(self, components: list) -> dict:
        """Charge le contexte Figma via MCP pour les composants"""
        context = {}
        
        # Import MCP tools
        sys.path.insert(0, str(PROJECT_ROOT))
        try:
            from mcp_solaris_server import SolarisMCPServer
            server = SolarisMCPServer()
            
            for comp in components[:3]:  # Limit to 3 components
                try:
                    # MCP methods are async
                    data = await server.get_component(comp, summary_only=True)
                    context[comp] = data
                except Exception as e:
                    context[comp] = {"error": str(e)}
        except ImportError:
            log("   Warning: Could not import MCP server")
        
        return context
    
    async def run_validation(self) -> Tuple[bool, str]:
        """Execute ./solaris validate"""
        try:
            result = subprocess.run(
                ["./solaris", "validate"],
                cwd=str(PROJECT_ROOT),
                capture_output=True,
                text=True,
                timeout=120
            )
            
            success = result.returncode == 0
            output = result.stdout + result.stderr
            
            return success, output[:2000]
        except subprocess.TimeoutExpired:
            return False, "Validation timeout"
        except Exception as e:
            return False, f"Validation error: {e}"
    
    async def process_task(self, task: dict) -> dict:
        """
        Process a single task with adversarial control and FRACTAL mode
        """
        task_id = task.get("id", "UNKNOWN")
        depth = task.get("fractal_depth", 0)
        
        # FRACTAL: v√©rifier si t√¢che trop large
        if self.should_decompose(task):
            subtasks = await self.decompose_task(task)
            if subtasks:
                # Traiter les sous-t√¢ches r√©cursivement
                results = []
                for st in subtasks:
                    result = await self.process_task(st)
                    results.append(result)
                
                # Agr√©ger les r√©sultats
                all_completed = all(r.get("status") == "completed" for r in results)
                if all_completed:
                    log(f"   ‚úÖ FRACTAL {task_id}: toutes les sous-t√¢ches compl√©t√©es")
                    return {"status": "completed", "task_id": task_id, "subtasks": results}
                else:
                    failed_count = sum(1 for r in results if r.get("status") == "failed")
                    log(f"   ‚ö†Ô∏è FRACTAL {task_id}: {failed_count}/{len(results)} sous-t√¢ches √©chou√©es")
                    return {"status": "partial", "task_id": task_id, "subtasks": results}
        
        # T√¢che atomique - traitement normal
        task_id = task.get("id", "UNKNOWN")
        description = task.get("description", "")
        components = task.get("components", [])
        criteria = task.get("acceptance_criteria", [])
        
        log(f"üìã Processing {task_id}: {description[:50]}...")
        
        # Build compact prompt (avoid timeout)
        prompt = f"""Expert Design System developer task.

TASK: {description}
COMPONENTS: {', '.join(components[:3])}
ACCEPTANCE CRITERIA:
{chr(10).join(f'- {c}' for c in criteria[:5])}

‚ö†Ô∏è R√àGLES STRICTES - VIOLATION = REJET IMM√âDIAT:

INTERDIT (score SLOP √©lev√©):
- test.skip, it.skip, describe.skip ‚Üí INTERDIT (10 pts)
- @ts-ignore ‚Üí INTERDIT (5 pts)
- TODO, FIXME, STUB, HACK ‚Üí INTERDIT (4 pts)
- ... (code tronqu√©) ‚Üí INTERDIT (3 pts)
- NotImplemented, pass vide ‚Üí INTERDIT (5 pts)

OVERCONFIDENT CLAIMS INTERDITES:
- "ensures", "guarantees", "always" ‚Üí INTERDIT (3 pts)
- "perfect", "flawless", "100%" ‚Üí INTERDIT (5 pts)
- "no issues", "no problems", "all good" ‚Üí INTERDIT (4 pts)
- "fully tested", "fully validated" ‚Üí INTERDIT (4 pts)

OBLIGATOIRE:
- Valeurs Figma via MCP solaris_variant() - pas de valeurs hardcod√©es
- Code complet et fonctionnel
- Tests r√©els sans skip

Generate the fix/implementation:"""
        
        # Retry loop with adversarial control
        for attempt in range(1, MAX_RETRIES + 1):
            log(f"   Attempt {attempt}/{MAX_RETRIES}...")
            
            # Generate code
            response = await self.call_wiggum(prompt)
            
            # Adversarial check
            approved, score, issues = self.adversarial.analyze(response, description)
            
            if approved:
                log(f"   ‚úÖ Adversarial APPROVED (score: {score})")
                break
            else:
                log(f"   ‚ùå Adversarial REJECTED (score: {score})")
                for issue in issues:
                    log(f"      {issue}")
                
                # Add feedback to prompt for retry
                feedback = self.adversarial.format_feedback(issues)
                prompt = f"{feedback}\n\nPROMPT ORIGINAL:\n{prompt}\n\nR√âPONSE PR√âC√âDENTE (REJET√âE):\n{response[:1000]}"
                
                await asyncio.sleep(RETRY_DELAY)
        else:
            # Max retries reached
            log(f"   ‚ö†Ô∏è Max retries reached for {task_id}")
            self.failed.append({
                "task": task,
                "reason": "max_retries",
                "last_issues": issues
            })
            return {"status": "failed", "task_id": task_id, "reason": "max_retries"}
        
        # Run validation
        log("   üîç Running ./solaris validate...")
        valid, output = await self.run_validation()
        
        if valid:
            log(f"   ‚úÖ Validation PASSED")
            self.completed.append({
                "task": task,
                "response": response[:5000],
                "completed_at": datetime.now().isoformat()
            })
            return {"status": "completed", "task_id": task_id}
        else:
            log(f"   ‚ö†Ô∏è Validation FAILED")
            self.failed.append({
                "task": task,
                "reason": "validation_failed",
                "output": output
            })
            return {"status": "failed", "task_id": task_id, "reason": "validation_failed"}
    
    def load_backlog(self) -> list:
        """Load tasks from backlog"""
        if not BACKLOG_FILE.exists():
            log("‚ö†Ô∏è No backlog found. Run lrm_brain_solaris.py first.")
            return []
        
        with open(BACKLOG_FILE) as f:
            data = json.load(f)
        
        return data.get("tasks", [])
    
    def save_completed(self):
        """Save completed and failed tasks"""
        data = {
            "completed": self.completed,
            "failed": self.failed,
            "updated_at": datetime.now().isoformat()
        }
        
        with open(COMPLETED_FILE, "w") as f:
            json.dump(data, f, indent=2)
    
    async def run(self, daemon: bool = False):
        """
        Run Wiggum agent
        
        Args:
            daemon: If True, run continuously watching for new tasks
        """
        log("=" * 60)
        log("üîß WIGGUM SOLARIS - Starting...")
        log("=" * 60)
        
        while True:
            tasks = self.load_backlog()
            
            if not tasks:
                if daemon:
                    log("üí§ No tasks. Sleeping 30s...")
                    await asyncio.sleep(30)
                    continue
                else:
                    log("‚úÖ No tasks to process")
                    break
            
            # Filter out already completed tasks
            completed_ids = {t["task"]["id"] for t in self.completed}
            pending = [t for t in tasks if t.get("id") not in completed_ids]
            
            if not pending:
                if daemon:
                    log("üí§ All tasks complete. Sleeping 30s...")
                    await asyncio.sleep(30)
                    continue
                else:
                    log("‚úÖ All tasks completed")
                    break
            
            log(f"üìã {len(pending)} tasks pending")
            
            # Process tasks
            for task in pending:
                result = await self.process_task(task)
                self.save_completed()
                
                if result["status"] == "failed":
                    log(f"   Task {result['task_id']} failed, continuing...")
            
            if not daemon:
                break
        
        # Final summary
        log("=" * 60)
        log("üìä WIGGUM SUMMARY")
        log(f"   Completed: {len(self.completed)}")
        log(f"   Failed: {len(self.failed)}")
        log("=" * 60)


async def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Wiggum Solaris Agent")
    parser.add_argument("--daemon", action="store_true", help="Run as daemon")
    args = parser.parse_args()
    
    wiggum = WiggumSolaris()
    await wiggum.run(daemon=args.daemon)


if __name__ == "__main__":
    asyncio.run(main())
