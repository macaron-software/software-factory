[0;36m[REPL 10:37:34] Context initialized: 5 keys
[0m[1;35m[RLM 10:37:34] RLM initialized[0m
[1;35m[RLM 10:37:34] === RLM START ===[0m
[1;35m[RLM 10:37:34] Query: Analyse le projet Veligo et g√©n√®re 5 t√¢ches TDD prioritaires.

√âTAPES:
1. RECURSE("Trouve tous les test.skip et tests qui √©chouent", "tests/")
2. RECURSE("Analyse les specs AO non impl√©ment√©es", "ao/")
3. RECURSE("Liste les TODO/FIXME critiques", "src/")

Puis agr√®ge et retourne:
FINAL([
  {"id": "T001", "title": "...", "priority": "P0", "wsjf": 9},
  ...
])
[0m
[1;35m[RLM 10:37:34] Executing: Analyse le projet Veligo et g√©n√®re 5 t√¢ches TDD pr...[0m
[1;35m[RLM 10:37:34] Calling LLM (depth=0)...[0m
[1;35m[RLM 10:37:34] Trying model: opencode/minimax-m2.1-free[0m
[1;35m[RLM 10:45:36] Model opencode/minimax-m2.1-free failed (code -9), trying fallback...[0m
[1;35m[RLM 10:45:36] Trying model: local/qwen3-30b-a3b[0m
[1;35m[RLM 11:14:33] Model local/qwen3-30b-a3b failed (code 1), trying fallback...[0m
Traceback (most recent call last):
  File "/Users/sylvain/_LAPOSTE/_VELIGO2/tools/ralph-wiggum/lrm_brain.py", line 685, in <module>
    main()
    ~~~~^^
  File "/Users/sylvain/_LAPOSTE/_VELIGO2/tools/ralph-wiggum/lrm_brain.py", line 675, in main
    tasks = generate_backlog(rlm)
  File "/Users/sylvain/_LAPOSTE/_VELIGO2/tools/ralph-wiggum/lrm_brain.py", line 575, in generate_backlog
    result = rlm.run(query)
  File "/Users/sylvain/_LAPOSTE/_VELIGO2/tools/ralph-wiggum/lrm_brain.py", line 536, in run
    result = self._execute_call(self.root_call)
  File "/Users/sylvain/_LAPOSTE/_VELIGO2/tools/ralph-wiggum/lrm_brain.py", line 476, in _execute_call
    response = self._call_llm(call.query, call.depth)
  File "/Users/sylvain/_LAPOSTE/_VELIGO2/tools/ralph-wiggum/lrm_brain.py", line 418, in _call_llm
    raise RuntimeError(f"Both LLM models failed at depth={depth}")
RuntimeError: Both LLM models failed at depth=0
